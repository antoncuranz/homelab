app-template:
  controllers:
    litellm:
      strategy: RollingUpdate
      containers:
        main:
          image: &image
            repository: ghcr.io/berriai/litellm-non_root
            tag: main-v1.80.0.rc.2
          env:
            TZ: "Europe/Berlin"
            LITELLM_MODE: "production"
            LITELLM_DONT_SHOW_FEEDBACK_BOX: "True"
            DATABASE_URL:
              valueFrom:
                secretKeyRef:
                  name: database-litellm-user
                  key: POSTGRES_URL
          envFrom:
            - secretRef:
                name: ai-secrets
          args:
            - --port
            - "4000"
            - --config
            - /app/config.yaml
          probes:
            liveness: &liveness
              enabled: true
              custom: true
              spec:
                httpGet:
                  path: /health/liveliness
                  port: 4000
            readiness: &readiness
              enabled: true
              custom: true
              spec:
                httpGet:
                  path: /health/readiness
                  port: 4000
          securityContext: &securityContext
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities: { drop: [ "ALL" ] }
      pod: &pod
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          fsGroup: 1000
          fsGroupChangePolicy: OnRootMismatch
          seccompProfile: { type: RuntimeDefault }

    cliproxyapi:
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: eceasy/cli-proxy-api
            tag: v6.5.12
          env:
            TZ: "Europe/Berlin"

    copilot1:
      replicas: 0
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: ghcr.io/ericc-ch/copilot-api
            tag: v0.7.0
          env:
            TZ: "Europe/Berlin"
            GH_TOKEN:
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: GH_TOKEN_1
          securityContext: *securityContext
      pod: *pod

    copilot2:
      replicas: 0
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: ghcr.io/ericc-ch/copilot-api
            tag: v0.7.0
          env:
            TZ: "Europe/Berlin"
            GH_TOKEN:
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: GH_TOKEN_2
          securityContext: *securityContext
      pod: *pod

  service:
    litellm:
      controller: litellm
      ports:
        http:
          port: 4000
    cliproxyapi:
      controller: cliproxyapi
      ports:
        http:
          port: 8317
    copilot1:
      controller: copilot1
      ports:
        http:
          port: 4141
    copilot2:
      controller: copilot2
      ports:
        http:
          port: 4141

  ingress:
    litellm:
      enabled: true
      className: nginx
      annotations:
        external-dns.alpha.kubernetes.io/target: "lb1.serverton.de"
        cert-manager.io/cluster-issuer: letsencrypt-prod
      hosts:
        - host: &host "aikeys.serverton.de"
          paths:
            - path: /
              service:
                identifier: litellm
                port: http
      tls:
        - secretName: litellm-tls-certificate
          hosts:
            - *host

  persistence:
    authdirs:
      enabled: true
      accessMode: ReadWriteOnce
      size: 250Mi
      advancedMounts:
        cliproxyapi:
          main:
            - path: /root/.cli-proxy-api
              subPath: cliproxyapi
        litellm:
          main:
            - path: /app/.config
              subPath: litellm

    configs:
      type: configMap
      name: ai-configs
      advancedMounts:
        litellm:
          main:
            - path: /app/config.yaml
              subPath: litellm.yaml
        cliproxyapi:
          main:
            - path: /CLIProxyAPI/config.yaml
              subPath: cliproxyapi.yaml

    tmpfs:
      type: emptyDir
      globalMounts:
        - path: /.cache
          subPath: cache
        - path: /.npm
          subPath: npm
        - path: /tmp
          subPath: tmp
        - path: /usr/lib/python3.13/site-packages/litellm_proxy_extras/migrations
          subPath: migrations
        - path: /home/bun/.local/share/copilot-api
          subPath: copilot-api

open-webui:
  ollama:
    enabled: false
  pipelines:
    enabled: false

  image:
    tag: "v0.6.36"

  ingress:
    enabled: true
    class: nginx
    annotations:
      external-dns.alpha.kubernetes.io/target: "lb1.serverton.de"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    host: gpt.serverton.de
    tls: true
    existingSecret: gpt-tls-certificate

  extraEnvVars:
    - name: ENABLE_EVALUATION_ARENA_MODELS
      value: "false"
    - name: ENABLE_MESSAGE_RATING
      value: "false"
    - name: ENABLE_COMMUNITY_SHARING
      value: "false"
    - name: ENABLE_VERSION_UPDATE_CHECK
      value: "false"
    - name: DATABASE_URL
      valueFrom:
        secretKeyRef:
          name: database-open-webui-user
          key: POSTGRES_URL

  persistence:
    enabled: true
    size: 2Gi
    accessModes:
      - ReadWriteOnce

librechat:
  global:
    librechat:
      existingSecretName: librechat-secrets
  librechat:
    configEnv:
      DOMAIN_CLIENT: "https://chat.serverton.de"
      DOMAIN_SERVER: "https://chat.serverton.de"
      ALLOW_EMAIL_LOGIN: "false"
      ALLOW_REGISTRATION: "true"
      ALLOW_SOCIAL_LOGIN: "true"
      ALLOW_SOCIAL_REGISTRATION: "true"
      OPENID_ISSUER: "https://keycloak.serverton.de/realms/serverton"
      OPENID_CLIENT_ID: "librechat"
      OPENID_CALLBACK_URL: "/oauth/openid/callback"
      OPENID_SCOPE: "openid profile email"
      OPENID_BUTTON_LABEL: "Login with Serverton"
    existingSecretName: librechat-secrets
    configYamlContent: |
      version: 1.0.8
      endpoints:
        custom:
          - name: "LiteLLM"
            apiKey: "${LITELLM_API_KEY}"
            baseURL: "http://ai-litellm:4000"
            models:
              default: ["gemini-2.5-pro"]
              fetch: true
            titleConvo: true
            titleModel: "gpt-4.1"
            summarize: false
            summaryModel: "gpt-4.1"
            forcePrompt: false
            modelDisplayLabel: "LiteLLM"
  mongodb:
    global:
      security:
        allowInsecureImages: true
    image:
      registry: registry-1.docker.io
      repository: bitnami/mongodb
      tag: latest
  ingress:
    enabled: true
    className: nginx
    annotations:
      external-dns.alpha.kubernetes.io/target: "lb1.serverton.de"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - host: &host chat.serverton.de
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls:
      - secretName: chat-tls-certificate
        hosts:
          - *host
  meilisearch:
    auth:
      existingMasterKeySecret: librechat-secrets