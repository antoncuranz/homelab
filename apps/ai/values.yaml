app-template:
  controllers:
    litellm:
      strategy: RollingUpdate
      containers:
        main:
          image: &image
            repository: ghcr.io/berriai/litellm-non_root
            tag: main-v1.80.10.rc.4
          env:
            TZ: "Europe/Berlin"
            LITELLM_MODE: "production"
            LITELLM_DONT_SHOW_FEEDBACK_BOX: "True"
            DATABASE_URL:
              valueFrom:
                secretKeyRef:
                  name: database-litellm-user
                  key: POSTGRES_URL
          envFrom:
            - secretRef:
                name: ai-secrets
          args:
            - --port
            - "4000"
            - --config
            - /app/config.yaml
          probes:
            liveness: &liveness
              enabled: true
              custom: true
              spec:
                httpGet:
                  path: /health/liveliness
                  port: 4000
            readiness: &readiness
              enabled: true
              custom: true
              spec:
                httpGet:
                  path: /health/readiness
                  port: 4000
          securityContext: &securityContext
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities: { drop: [ "ALL" ] }
      pod: &pod
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          fsGroup: 1000
          fsGroupChangePolicy: OnRootMismatch
          seccompProfile: { type: RuntimeDefault }

    cliproxyapi:
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: eceasy/cli-proxy-api
            tag: v6.6.38
          env:
            TZ: "Europe/Berlin"

    copilot1:
      replicas: 0
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: ghcr.io/ericc-ch/copilot-api
            tag: v0.7.0
          env:
            TZ: "Europe/Berlin"
            GH_TOKEN:
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: GH_TOKEN_1
          securityContext: *securityContext
      pod: *pod

    copilot2:
      replicas: 0
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: ghcr.io/ericc-ch/copilot-api
            tag: v0.7.0
          env:
            TZ: "Europe/Berlin"
            GH_TOKEN:
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: GH_TOKEN_2
          securityContext: *securityContext
      pod: *pod

    gemini:
      strategy: RollingUpdate
      containers:
        main:
          image:
            repository: ghcr.io/antoncuranz/geminicli2api
            tag: latest
            pullPolicy: Always
          env:
            GEMINI_AUTH_PASSWORD: "sk-dummy"
            PORT: "8888"
            GEMINI_CREDENTIALS:
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: GEMINI_CREDENTIALS
#          securityContext: *securityContext
#      pod: *pod

  service:
    litellm:
      controller: litellm
      ports:
        http:
          port: 4000
    cliproxyapi:
      controller: cliproxyapi
      ports:
        http:
          port: 8317
    copilot1:
      controller: copilot1
      ports:
        http:
          port: 4141
    copilot2:
      controller: copilot2
      ports:
        http:
          port: 4141
    gemini:
      controller: gemini
      ports:
        http:
          port: 8888

  ingress:
    litellm:
      enabled: true
      className: nginx
      annotations:
        external-dns.alpha.kubernetes.io/target: "lb1.serverton.de"
        cert-manager.io/cluster-issuer: letsencrypt-prod
      hosts:
        - host: &host "aikeys.serverton.de"
          paths:
            - path: /
              service:
                identifier: litellm
                port: http
      tls:
        - secretName: litellm-tls-certificate
          hosts:
            - *host

  persistence:
    authdirs:
      enabled: true
      accessMode: ReadWriteOnce
      size: 250Mi
      advancedMounts:
        cliproxyapi:
          main:
            - path: /root/.cli-proxy-api
              subPath: cliproxyapi
        litellm:
          main:
            - path: /app/.config
              subPath: litellm

    configs:
      type: configMap
      name: ai-configs
      advancedMounts:
        litellm:
          main:
            - path: /app/config.yaml
              subPath: litellm.yaml
        cliproxyapi:
          main:
            - path: /CLIProxyAPI/config.yaml
              subPath: cliproxyapi.yaml

    tmpfs:
      type: emptyDir
      globalMounts:
        - path: /.cache
          subPath: cache
        - path: /.npm
          subPath: npm
        - path: /tmp
          subPath: tmp
        - path: /usr/lib/python3.13/site-packages/litellm_proxy_extras/migrations
          subPath: migrations
        - path: /home/bun/.local/share/copilot-api
          subPath: copilot-api

librechat:
  global:
    librechat:
      existingSecretName: librechat-secrets
  librechat:
    configEnv:
      DOMAIN_CLIENT: "https://chat.serverton.de"
      DOMAIN_SERVER: "https://chat.serverton.de"
      ALLOW_EMAIL_LOGIN: "false"
      ALLOW_REGISTRATION: "false"
      ALLOW_SOCIAL_LOGIN: "true"
      ALLOW_SOCIAL_REGISTRATION: "false"
      OPENID_ISSUER: "https://keycloak.serverton.de/realms/serverton"
      OPENID_CLIENT_ID: "librechat"
      OPENID_CALLBACK_URL: "/oauth/openid/callback"
      OPENID_SCOPE: "openid profile email"
      OPENID_BUTTON_LABEL: "Login with serverton"
    existingSecretName: librechat-secrets
    configYamlContent: |
      version: 1.0.8
      endpoints:
        custom:
          - name: "serverton"
            apiKey: "${LITELLM_API_KEY}"
            baseURL: "http://ai-litellm:4000"
            models:
              default: ["gemini-3-pro-preview"]
              fetch: true
            titleConvo: true
            titleModel: "gpt-4.1"
            summaryModel: "gpt-4.1"
            modelDisplayLabel: "Serverton"
      modelSpecs:
        list:
          - name: "gemini-3-pro-preview"
            label: "Google Gemini 3 Pro"
            default: true
            description: "Das beste von Google."
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/dark/gemini-color.png"
            preset:
              endpoint: "serverton"
              model: "gemini-3-pro-preview"
              modelLabel: "Gemini 3 Pro"
          - name: "gemini-2.5-pro"
            label: "Google Gemini 2.5 Pro"
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/dark/gemini-color.png"
            preset:
              endpoint: "serverton"
              model: "gemini-2.5-pro"
              modelLabel: "Gemini 2.5 Pro"
          - name: "gemini-2.5-flash"
            label: "Google Gemini 2.5 Flash"
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/dark/gemini-color.png"
            preset:
              endpoint: "serverton"
              model: "gemini-2.5-flash"
              modelLabel: "Gemini 2.5 Flash"
          - name: "gpt-5-mini"
            label: "OpenAI GPT 5 mini"
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/light/openai.png"
            preset:
              endpoint: "serverton"
              model: "gpt-5-mini"
          - name: "gpt-4o"
            label: "OpenAI GPT 4o"
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/light/openai.png"
            preset:
              endpoint: "serverton"
              model: "gpt-4o"
          - name: "gpt-4.1"
            label: "OpenAI GPT 4.1"
            iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/light/openai.png"
            preset:
              endpoint: "serverton"
              model: "gpt-4.1"
  mongodb:
    global:
      security:
        allowInsecureImages: true
    image:
      registry: registry-1.docker.io
      repository: bitnami/mongodb
      tag: latest
  ingress:
    enabled: true
    className: nginx
    annotations:
      external-dns.alpha.kubernetes.io/target: "lb1.serverton.de"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - host: &host chat.serverton.de
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls:
      - secretName: chat-tls-certificate
        hosts:
          - *host
  meilisearch:
    auth:
      existingMasterKeySecret: librechat-secrets